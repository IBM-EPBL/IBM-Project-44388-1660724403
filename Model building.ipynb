{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1684438c",
   "metadata": {},
   "source": [
    "# Importing the Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84869306",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23b1583",
   "metadata": {},
   "source": [
    "# Initializing the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "becc7562",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4d5bc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(32,3,3,input_shape=(64,64,3),activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "592cc027",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48a2df4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "18a0cc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=128,activation='relu',kernel_initializer ='random_uniform'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14971ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=1,activation='sigmoid',kernel_initializer ='random_uniform'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e45e1377",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0f47ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8389705",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen=ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9f4238c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4118 images belonging to 5 classes.\n",
      "Found 929 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "x_train = train_datagen.flow_from_directory(r'E:\\Dataset\\TRAIN_SET',target_size=(64,64),batch_size=32,class_mode='binary')\n",
    "x_test = train_datagen.flow_from_directory(r'E:\\Dataset\\TEST_SET',target_size=(64,64),batch_size=32,class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "60f2eef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'APPLES': 0, 'BANANA': 1, 'ORANGE': 2, 'PINEAPPLE': 3, 'WATERMELON': 4}\n"
     ]
    }
   ],
   "source": [
    "print(x_train.class_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7e5d1ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_11000\\984688948.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(x_train,steps_per_epoch=len(x_train), validation_data=x_test, validation_steps=len(x_test), epochs= 25)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "129/129 [==============================] - 182s 1s/step - loss: -2038.3542 - accuracy: 0.3278 - val_loss: 312.1045 - val_accuracy: 0.4467\n",
      "Epoch 2/25\n",
      "129/129 [==============================] - 17s 127ms/step - loss: -44526.7812 - accuracy: 0.3288 - val_loss: 3694.8027 - val_accuracy: 0.4467\n",
      "Epoch 3/25\n",
      "129/129 [==============================] - 16s 122ms/step - loss: -235414.4062 - accuracy: 0.3288 - val_loss: 12859.5625 - val_accuracy: 0.4467\n",
      "Epoch 4/25\n",
      "129/129 [==============================] - 16s 122ms/step - loss: -671487.5625 - accuracy: 0.3288 - val_loss: 34459.3008 - val_accuracy: 0.4467\n",
      "Epoch 5/25\n",
      "129/129 [==============================] - 19s 144ms/step - loss: -1447473.3750 - accuracy: 0.3288 - val_loss: 69642.6719 - val_accuracy: 0.4467\n",
      "Epoch 6/25\n",
      "129/129 [==============================] - 24s 189ms/step - loss: -2640501.0000 - accuracy: 0.3288 - val_loss: 110534.5312 - val_accuracy: 0.4467\n",
      "Epoch 7/25\n",
      "129/129 [==============================] - 22s 170ms/step - loss: -4352383.5000 - accuracy: 0.3288 - val_loss: 168102.7812 - val_accuracy: 0.4467\n",
      "Epoch 8/25\n",
      "129/129 [==============================] - 22s 169ms/step - loss: -6604431.5000 - accuracy: 0.3288 - val_loss: 266704.9688 - val_accuracy: 0.4467\n",
      "Epoch 9/25\n",
      "129/129 [==============================] - 24s 182ms/step - loss: -9497671.0000 - accuracy: 0.3288 - val_loss: 389238.2500 - val_accuracy: 0.4467\n",
      "Epoch 10/25\n",
      "129/129 [==============================] - 22s 170ms/step - loss: -12866258.0000 - accuracy: 0.3288 - val_loss: 490967.6562 - val_accuracy: 0.4467\n",
      "Epoch 11/25\n",
      "129/129 [==============================] - 23s 176ms/step - loss: -16931318.0000 - accuracy: 0.3288 - val_loss: 623982.7500 - val_accuracy: 0.4467\n",
      "Epoch 12/25\n",
      "129/129 [==============================] - 24s 187ms/step - loss: -21948044.0000 - accuracy: 0.3288 - val_loss: 820289.6250 - val_accuracy: 0.4467\n",
      "Epoch 13/25\n",
      "129/129 [==============================] - 22s 174ms/step - loss: -27539138.0000 - accuracy: 0.3288 - val_loss: 987234.8125 - val_accuracy: 0.4467\n",
      "Epoch 14/25\n",
      "129/129 [==============================] - 18s 135ms/step - loss: -33800856.0000 - accuracy: 0.3288 - val_loss: 1121535.2500 - val_accuracy: 0.4467\n",
      "Epoch 15/25\n",
      "129/129 [==============================] - 18s 143ms/step - loss: -41152876.0000 - accuracy: 0.3288 - val_loss: 1524781.6250 - val_accuracy: 0.4467\n",
      "Epoch 16/25\n",
      "129/129 [==============================] - 18s 139ms/step - loss: -49127388.0000 - accuracy: 0.3288 - val_loss: 1921663.7500 - val_accuracy: 0.4467\n",
      "Epoch 17/25\n",
      "129/129 [==============================] - 20s 152ms/step - loss: -57955060.0000 - accuracy: 0.3288 - val_loss: 2220694.2500 - val_accuracy: 0.4467\n",
      "Epoch 18/25\n",
      "129/129 [==============================] - 18s 141ms/step - loss: -67763160.0000 - accuracy: 0.3288 - val_loss: 2581001.2500 - val_accuracy: 0.4467\n",
      "Epoch 19/25\n",
      "129/129 [==============================] - 19s 144ms/step - loss: -78054112.0000 - accuracy: 0.3288 - val_loss: 2865403.5000 - val_accuracy: 0.4467\n",
      "Epoch 20/25\n",
      "129/129 [==============================] - 19s 146ms/step - loss: -89322680.0000 - accuracy: 0.3288 - val_loss: 2989759.2500 - val_accuracy: 0.4467\n",
      "Epoch 21/25\n",
      "129/129 [==============================] - 18s 140ms/step - loss: -101843696.0000 - accuracy: 0.3288 - val_loss: 3724234.0000 - val_accuracy: 0.4467\n",
      "Epoch 22/25\n",
      "129/129 [==============================] - 19s 148ms/step - loss: -115483528.0000 - accuracy: 0.3288 - val_loss: 4223153.0000 - val_accuracy: 0.4467\n",
      "Epoch 23/25\n",
      "129/129 [==============================] - 17s 130ms/step - loss: -129700816.0000 - accuracy: 0.3288 - val_loss: 4441666.0000 - val_accuracy: 0.4467\n",
      "Epoch 24/25\n",
      "129/129 [==============================] - 18s 142ms/step - loss: -145193616.0000 - accuracy: 0.3288 - val_loss: 5221810.5000 - val_accuracy: 0.4467\n",
      "Epoch 25/25\n",
      "129/129 [==============================] - 19s 145ms/step - loss: -161497792.0000 - accuracy: 0.3288 - val_loss: 5631668.0000 - val_accuracy: 0.4467\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2324ba54640>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(x_train,steps_per_epoch=len(x_train), validation_data=x_test, validation_steps=len(x_test), epochs= 25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b78640ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('mymodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "60102c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "109ada32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import cv2\n",
    "model = load_model('mymodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "445eb64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dadf1447",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "def detect(frame):\n",
    "    try:\n",
    "        img = resize(frame,64,64)\n",
    "        img = np.expand_dims(img,axis=0)\n",
    "        if(np.max(img)>1):\n",
    "            img = img/225.0\n",
    "            prediction = model.predict(img)\n",
    "            print(prediction)\n",
    "            prdiction_class = model.pedict_classes(img)\n",
    "            print(prediction_class)\n",
    "    except AttributeError:\n",
    "                print(\"shape not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82227d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = cv2.imread(\"cat.jpg\")\n",
    "frame"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
